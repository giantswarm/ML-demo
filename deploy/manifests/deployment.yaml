apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-demo
  labels:
    app: ml-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-demo
  template:
    metadata:
      labels:
        app: ml-demo
    spec:
      containers:
      - name: ml-demo
        image: gsoci.azurecr.io/giantswarm/ml-example:1.0.0
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
            nvidia.com/gpu: 1
          limits:
            cpu: 500m
            memory: 512Mi
            nvidia.com/gpu: 1
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 10
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          seccompProfile:
            type: RuntimeDefault
      runtimeClassName: nvidia
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
---
apiVersion: v1
kind: Service
metadata:
  name: ml-demo
spec:
  selector:
    app: ml-demo
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: ClusterIP